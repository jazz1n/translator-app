{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9265415,"sourceType":"datasetVersion","datasetId":5606819}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Named Entity Extraction using GLiNER\n\n### Team: Tensor Titans\n### Ghazal Askari, Mohammadreza Vilani, Sepideh Soleimanian, Amirhosein Rajabi, Yasamin Sarrafi","metadata":{}},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-28T10:13:08.030494Z","iopub.execute_input":"2024-08-28T10:13:08.030970Z","iopub.status.idle":"2024-08-28T10:13:08.044147Z","shell.execute_reply.started":"2024-08-28T10:13:08.030925Z","shell.execute_reply":"2024-08-28T10:13:08.042959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q gliner\nfrom gliner import GLiNER","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-08-28T10:13:11.555072Z","iopub.execute_input":"2024-08-28T10:13:11.555508Z","iopub.status.idle":"2024-08-28T10:13:32.047859Z","shell.execute_reply.started":"2024-08-28T10:13:11.555441Z","shell.execute_reply":"2024-08-28T10:13:32.046850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# available models: https://huggingface.co/urchade\n\nmodel = GLiNER.from_pretrained(\"urchade/gliner_multi-v2.1\")\nmodel.eval()\nprint(\"ok\")","metadata":{"execution":{"iopub.status.busy":"2024-08-28T10:14:33.062720Z","iopub.execute_input":"2024-08-28T10:14:33.063337Z","iopub.status.idle":"2024-08-28T10:15:08.287770Z","shell.execute_reply.started":"2024-08-28T10:14:33.063292Z","shell.execute_reply":"2024-08-28T10:15:08.286474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here, we verify our model works, with a simple sentence:","metadata":{}},{"cell_type":"code","source":"# to do (edit labels)\n\ntext = \"\"\"\nپرستو در پایان هفته به رهنما کالج رفت و در اسنپ با دوستانش درباره کتاب موراکامی -کافکا در کرانه- صحبت کرد\n\"\"\"\n\nlabels = [\"person\", \"location\", \"date\", \"organization\", \"book\"]\n\n# Lower the threshold to increase how many entities get predicted\nentities = model.predict_entities(text, labels, threshold=0.2)\n\nfor entity in entities:\n    print(entity[\"text\"], \"=>\", entity[\"label\"])","metadata":{"execution":{"iopub.status.busy":"2024-08-28T10:15:21.491925Z","iopub.execute_input":"2024-08-28T10:15:21.492573Z","iopub.status.idle":"2024-08-28T10:15:21.955137Z","shell.execute_reply.started":"2024-08-28T10:15:21.492525Z","shell.execute_reply":"2024-08-28T10:15:21.953908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndf = pd.read_csv(\"/kaggle/input/cleaned-infopannki-fa/cleaned_infopankki-fa.csv\")\ndf = df[[\"Persian\",\"English\"]] # needed columns","metadata":{"execution":{"iopub.status.busy":"2024-08-28T10:17:56.454371Z","iopub.execute_input":"2024-08-28T10:17:56.454809Z","iopub.status.idle":"2024-08-28T10:17:56.463988Z","shell.execute_reply.started":"2024-08-28T10:17:56.454767Z","shell.execute_reply":"2024-08-28T10:17:56.462892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define your labels\nlabels = [\"person\", \"location\", \"date\", \"organization\", \"language\", \"book\", \"movie\"]\n\n# Function to get tags for a sentence\ndef get_tags_for_sentence(sentence, model, labels, threshold=0.3):\n    entities = model.predict_entities(sentence, labels, threshold=threshold)\n    # Initialize the list with '0's\n    words = sentence.split()\n    tags = ['0'] * len(words)\n\n    # Map each word to its tag\n    for entity in entities:\n        entity_words = entity[\"text\"].split()\n        entity_label = entity[\"label\"]\n        start_idx = next(i for i, word in enumerate(words) if word == entity_words[0])\n        for i in range(len(entity_words)):\n            tags[start_idx + i] = entity_label\n\n    return ' '.join(tags)","metadata":{"execution":{"iopub.status.busy":"2024-08-28T10:18:06.181190Z","iopub.execute_input":"2024-08-28T10:18:06.182250Z","iopub.status.idle":"2024-08-28T10:18:06.189296Z","shell.execute_reply.started":"2024-08-28T10:18:06.182201Z","shell.execute_reply":"2024-08-28T10:18:06.188123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### using the function get_tag_for_sentence,  we do NER for the Persian Column of our model and saved the info as a string, in the column 'Fa NER'","metadata":{}},{"cell_type":"code","source":"# Apply the function to each row in the DataFrame\ndf['Fa NER'] = df['Persian'].apply(lambda x: get_tags_for_sentence(x, model, labels))\n\n# Save the DataFrame to a CSV file\ndf.to_csv('ner_infopannki_output.csv', index=False)\n\nprint(\"NER tagging completed and saved to ner_output.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-08-28T10:26:46.910845Z","iopub.execute_input":"2024-08-28T10:26:46.911313Z","iopub.status.idle":"2024-08-28T10:27:13.171726Z","shell.execute_reply.started":"2024-08-28T10:26:46.911271Z","shell.execute_reply":"2024-08-28T10:27:13.170400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now we can randomly select some rows, to inspect the new NER column. ","metadata":{}},{"cell_type":"code","source":"df_output = pd.read_csv('/kaggle/working/ner_infopannki_output.csv')\n\ndf_output[[\"Persian\", \"Fa NER\"]].iloc[80:]","metadata":{"execution":{"iopub.status.busy":"2024-08-28T10:31:58.879627Z","iopub.execute_input":"2024-08-28T10:31:58.880079Z","iopub.status.idle":"2024-08-28T10:31:58.896492Z","shell.execute_reply.started":"2024-08-28T10:31:58.880034Z","shell.execute_reply":"2024-08-28T10:31:58.895136Z"},"trusted":true},"execution_count":null,"outputs":[]}]}